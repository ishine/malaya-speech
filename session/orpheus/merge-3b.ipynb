{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a802f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9386273d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a8aa74051c40d9948ea1ad1a99527b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/husein/ssd3/tts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(repo_id=\"mesolitica/malay-orpheus-3b-0.1-ft-lora-128\", \n",
    "                  allow_patterns=\"*.safetensors\",\n",
    "                  local_dir = './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf5e7ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "import torch\n",
    "\n",
    "def redistribute_codes(row):\n",
    "    row_length = row.size(0)\n",
    "    new_length = (row_length // 7) * 7\n",
    "    trimmed_row = row[:new_length]\n",
    "    code_list = [t - 128266 for t in trimmed_row]\n",
    "    layer_1 = []\n",
    "    layer_2 = []\n",
    "    layer_3 = []\n",
    "    for i in range((len(code_list)+1)//7):\n",
    "        layer_1.append(code_list[7*i][None])\n",
    "        layer_2.append(code_list[7*i+1][None]-4096)\n",
    "        layer_3.append(code_list[7*i+2][None]-(2*4096))\n",
    "        layer_3.append(code_list[7*i+3][None]-(3*4096))\n",
    "        layer_2.append(code_list[7*i+4][None]-(4*4096))\n",
    "        layer_3.append(code_list[7*i+5][None]-(5*4096))\n",
    "        layer_3.append(code_list[7*i+6][None]-(6*4096))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        codes = [torch.concat(layer_1)[None], \n",
    "            torch.concat(layer_2)[None], \n",
    "            torch.concat(layer_3)[None]]\n",
    "        audio_hat = snac_model.decode(codes)\n",
    "        return audio_hat.cpu()[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aff28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('canopylabs/orpheus-3b-0.1-ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a754c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae19ba3016664fc292cc1161ece4bb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ori_model = AutoModelForCausalLM.from_pretrained(\n",
    "    'canopylabs/orpheus-3b-0.1-ft', tie_word_embeddings=False\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c942651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_model.lm_head.weight.data = ori_model.model.embed_tokens.weight.data.clone()\n",
    "state_dict = ori_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a395434d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 198/198 [00:00<00:00, 458.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "from tqdm import tqdm\n",
    "\n",
    "f = safe_open(f\"adapter_model.safetensors\", framework=\"pt\", device=0)\n",
    "keys = f.keys()\n",
    "keys = sorted(list(set([k.split('.lora')[0] for k in keys if '.lora' in k])))\n",
    "\n",
    "for k in tqdm(keys):\n",
    "    k_ori = k.replace('base_model.model.', '') + '.weight'\n",
    "    if 'embed_tokens' in k:\n",
    "        post_A = '.lora_embedding_A'\n",
    "        post_B = '.lora_embedding_B'\n",
    "    else:\n",
    "        post_A = '.lora_A.weight'\n",
    "        post_B = '.lora_B.weight'\n",
    "    A = k + post_A\n",
    "    B = k + post_B\n",
    "    \n",
    "    W = state_dict[k_ori]\n",
    "    if 'embed_tokens' not in k:\n",
    "        W = W.t()\n",
    "        \n",
    "    A = f.get_tensor(A)\n",
    "    B = f.get_tensor(B)\n",
    "    with torch.no_grad():\n",
    "        W.addmm_(A.t(), B.t(), alpha = 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6de09dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snac import SNAC\n",
    "snac_model = SNAC.from_pretrained(\"hubertsiuzdak/snac_24khz\")\n",
    "snac_model = snac_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33eee89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = 'Husein'\n",
    "text = 'Nama saya Husein, <chuckle>, erm, saya tak suka nasi ayam dan tak suka mandi.'\n",
    "prompt = f'<custom_token_3><|begin_of_text|>{speaker}: {text}<|eot_id|><custom_token_4><custom_token_5><custom_token_1>'\n",
    "input_ids = tokenizer(prompt,add_special_tokens = False, return_tensors = 'pt').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee51a0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128258 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    generated_ids = ori_model.generate(\n",
    "      **input_ids,\n",
    "      max_new_tokens=1200,\n",
    "      do_sample=True,\n",
    "      temperature=0.9,\n",
    "      top_p=0.95,\n",
    "      repetition_penalty=1.1,\n",
    "      num_return_sequences=1,\n",
    "      eos_token_id=128258,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce9b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = generated_ids[0, input_ids['input_ids'].shape[1]:]\n",
    "y_ = redistribute_codes(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa1cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(y_, rate = 24000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
