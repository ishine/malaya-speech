accelerate launch run.py \
--model_name_or_path "parler-tts/parler-tts-mini-v1" \
--feature_extractor_name "parler-tts/dac_44khZ_8kbps" \
--description_tokenizer_name "google/flan-t5-large" \
--prompt_tokenizer_name "google/flan-t5-large" \
--report_to "wandb" \
--overwrite_output_dir false \
--train_dataset_name "huseinzol05/processed-tts-combine-annotated" \
--train_split_name "train" \
--eval_dataset_name "huseinzol05/processed-tts-combine-annotated" \
--eval_split_name "test" \
--target_audio_column_name "audio" \
--description_column_name "prompt" \
--prompt_column_name "transcription" \
--max_duration_in_seconds 30 \
--min_duration_in_seconds 2.0 \
--max_text_length 600 \
--add_audio_samples_to_wandb true \
--id_column_name "id" \
--preprocessing_num_workers 8 \
--do_train true \
--num_train_epochs 3 \
--gradient_accumulation_steps 4 \
--gradient_checkpointing false \
--per_device_train_batch_size 8 \
--learning_rate 0.00095 \
--adam_beta1 0.9 \
--adam_beta2 0.99 \
--weight_decay 0.01 \
--lr_scheduler_type "constant_with_warmup" \
--warmup_steps 2000 \
--logging_steps 2 \
--freeze_text_encoder true \
--do_eval true \
--predict_with_generate true \
--include_inputs_for_metrics true \
--evaluation_strategy steps \
--eval_steps 100000 \
--save_steps 100 \
--per_device_eval_batch_size 4 \
--audio_encoder_per_device_batch_size 24 \
--dtype "bfloat16" \
--seed 456 \
--output_dir "./output_dir_training-v3/" \
--temporary_save_to_disk "./audio_code_tmp/" \
--save_to_disk "./tmp_dataset_audio/" \
--max_eval_samples 96 \
--dataloader_num_workers 8 \
--group_by_length true \
--attn_implementation "sdpa" \
--save_total_limit 3