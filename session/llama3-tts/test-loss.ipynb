{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5b3292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96bab573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LlamaTTS\n",
    "from transformers.models.llama.modeling_llama import LlamaForCausalLM\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from transformers import DacModel, AutoProcessor\n",
    "from datasets import Audio\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "dac = DacModel.from_pretrained(\"descript/dac_44khz\")\n",
    "processor = AutoProcessor.from_pretrained(\"descript/dac_44khz\")\n",
    "audio = Audio(processor.sampling_rate)\n",
    "config = AutoConfig.from_pretrained('HuggingFaceTB/SmolLM2-135M-Instruct')\n",
    "tokenizer = AutoTokenizer.from_pretrained('HuggingFaceTB/SmolLM2-135M-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a24264a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaTTS were not initialized from the model checkpoint at HuggingFaceTB/SmolLM2-135M-Instruct and are newly initialized: ['codebook_heads.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = LlamaTTS.from_pretrained('HuggingFaceTB/SmolLM2-135M-Instruct', torch_dtype = torch.bfloat16).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86486bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50178, 576, padding_idx=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer) + model.config.codebook_size + 2, mean_resizing = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5de9ff63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61180"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_audio(f):\n",
    "    return audio.decode_example(audio.encode_example(f))['array']\n",
    "\n",
    "files = glob('/home/husein/ssd3/sg-podcast_processed/**/*.mp3', recursive = True)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "993e4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_audio(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb4d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(raw_audio=a, sampling_rate=processor.sampling_rate, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "938189c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 666])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    encoder_outputs = dac.encode(inputs[\"input_values\"]).audio_codes + len(tokenizer) + 2\n",
    "input_ids = tokenizer('helo testing', return_tensors = 'pt').input_ids\n",
    "input_ids = input_ids.unsqueeze(1).repeat((1, model.config.num_codebooks, 1))\n",
    "speech_start = torch.full((1, model.config.num_codebooks, 1), len(tokenizer))\n",
    "speech_end = torch.full((1, model.config.num_codebooks, 1), len(tokenizer) + 1)\n",
    "input_ids = torch.concat(\n",
    "    [encoder_outputs, input_ids, speech_start, encoder_outputs], dim = -1\n",
    ")\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f4800ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parler_tts import build_delay_pattern_mask, apply_delay_pattern_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef2b8c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[49852, 49484, 49957,  ..., 49153, 49153, 49153],\n",
       "         [49152, 49641, 49788,  ..., 49153, 49153, 49153],\n",
       "         [49152, 49152, 49918,  ..., 49153, 49153, 49153],\n",
       "         ...,\n",
       "         [49152, 49152, 49152,  ..., 49153, 49153, 49153],\n",
       "         [49152, 49152, 49152,  ..., 50000, 49153, 49153],\n",
       "         [49152, 49152, 49152,  ..., 49241, 49471, 49153]]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids, delay_pattern_mask = build_delay_pattern_mask(\n",
    "    input_ids[0],\n",
    "    bos_token_id=len(tokenizer),\n",
    "    pad_token_id=len(tokenizer) + 1,\n",
    "    max_length=input_ids.shape[-1] + model.num_codebooks,\n",
    "    num_codebooks=model.num_codebooks,\n",
    ")\n",
    "input_ids = torch.where(delay_pattern_mask == -1, len(tokenizer) + 1, delay_pattern_mask)\n",
    "input_ids = input_ids[:, 1:].unsqueeze(0).cuda()\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6cddc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[49852, 49484, 49957,  ..., 49153, 49153, 49153],\n",
       "         [ -100, 49641, 49788,  ..., 49153, 49153, 49153],\n",
       "         [ -100,  -100, 49918,  ..., 49153, 49153, 49153],\n",
       "         ...,\n",
       "         [ -100,  -100,  -100,  ..., 49153, 49153, 49153],\n",
       "         [ -100,  -100,  -100,  ..., 50000, 49153, 49153],\n",
       "         [ -100,  -100,  -100,  ..., 49241, 49471, 49153]]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = input_ids.masked_fill(input_ids == len(tokenizer), -100)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cfb7904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[49152, 49852, 49484,  ..., 49153, 49153, 49153],\n",
       "        [49152, 49152, 49641,  ..., 49153, 49153, 49153],\n",
       "        [49152, 49152, 49152,  ..., 49153, 49153, 49153],\n",
       "        ...,\n",
       "        [49152, 49152, 49152,  ...,    -1, 49153, 49153],\n",
       "        [49152, 49152, 49152,  ..., 50000,    -1, 49153],\n",
       "        [49152, 49152, 49152,  ..., 49241, 49471,    -1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_pattern_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bb3962f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1851, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids, labels = labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
