{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f94c0c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "/home/husein/.local/lib/python3.8/site-packages/whisper/timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n",
      "`pyaudio` is not available, `malaya_speech.streaming.pyaudio` is not able to use.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import malaya_speech\n",
    "from conformer import HF_CTC_VOCAB, melspectrogram, ConformerConfig, ConformerEncoder\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "HF_CTC_VOCAB_INDEX = {no: c for no, c in enumerate(HF_CTC_VOCAB)}\n",
    "HF_CTC_VOCAB_REV = {v: k for k, v in HF_CTC_VOCAB_INDEX.items()}\n",
    "\n",
    "ConformerConfig.register_for_auto_class()\n",
    "ConformerEncoder.register_for_auto_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b02a54c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ' ',\n",
       " '?',\n",
       " '_']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HF_CTC_VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1986c9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConformerConfig(\n",
    "    input_dim=80,\n",
    "    output_dim=len(HF_CTC_VOCAB),\n",
    "    time_reduction_stride=4,\n",
    "    conformer_input_dim=144,\n",
    "    conformer_ffn_dim=576,\n",
    "    conformer_num_layers=8,\n",
    "    conformer_num_heads=4,\n",
    "    conformer_depthwise_conv_kernel_size=31,\n",
    "    conformer_dropout=0.0,\n",
    "    pad_token_id=len(HF_CTC_VOCAB) - 1,\n",
    "    ctc_loss_reduction='mean',\n",
    "    ctc_zero_infinity=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e8284c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder = ConformerEncoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e00222",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_stats = torch_featurization.GlobalStatsNormalization('../../../malay-stats.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "809e5d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = malaya_speech.load('../../../speech/example-speaker/husein-zolkepli.wav')\n",
    "y2, sr = malaya_speech.load('../../../speech/example-speaker/shafiqah-idayu.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4b8c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "srs = [4400, 5100, 6000, 8000, 10000]\n",
    "\n",
    "def downsample(y, sr):\n",
    "    s_sr = random.choice(srs)\n",
    "    y_ = malaya_speech.resample(y, sr, s_sr)\n",
    "    return malaya_speech.resample(y_, s_sr, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6dc262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel = torch_featurization.melspectrogram(y)\n",
    "mel = torch_featurization.piecewise_linear_log(mel)\n",
    "mel2 = torch_featurization.melspectrogram(y2)\n",
    "mel2 = torch_featurization.piecewise_linear_log(mel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d049b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['nama saya husein bin zolkepli', 'nama saya shafiqah idayu']\n",
    "text = [[HF_CTC_VOCAB_REV[c] for c in t] for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "247924dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "     def __call__(self, features):\n",
    "        inputs = [f['inputs'] for f in features]\n",
    "        lengths = torch.tensor([len(f['inputs']) for f in features])\n",
    "        inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first = True)\n",
    "        labels = [torch.tensor(f['labels']) for f in features]\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first = True, padding_value = -100)\n",
    "        return {\n",
    "            'inputs': inputs,\n",
    "            'lengths': lengths,\n",
    "            'labels': labels,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b74b338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorCTCWithPadding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0de4278e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': tensor([[[ 7.5720,  8.8585, 11.1099,  ..., 14.2707, 14.0441, 14.6217],\n",
       "          [11.6262, 12.9127, 15.0601,  ..., 14.3029, 13.7059, 14.6847],\n",
       "          [15.4666, 16.7531, 17.1559,  ..., 12.7871, 13.4699, 14.2108],\n",
       "          ...,\n",
       "          [19.2897, 20.5761, 18.5907,  ..., 13.4430, 14.3961, 14.1888],\n",
       "          [19.9591, 21.2456, 20.8646,  ..., 13.4250, 13.9565, 14.0654],\n",
       "          [15.8479, 17.1344, 15.3638,  ..., 12.1170, 12.7841, 11.9480]],\n",
       " \n",
       "         [[13.5830, 14.8695, 16.0703,  ..., 16.1097, 15.8851, 15.7696],\n",
       "          [17.2102, 18.4967, 19.5340,  ..., 16.7923, 16.7401, 17.0030],\n",
       "          [19.9245, 21.2110, 21.4556,  ..., 17.6996, 17.4917, 17.0634],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]),\n",
       " 'lengths': tensor([564, 352]),\n",
       " 'labels': tensor([[  14,    1,   13,    1,   37,   19,    1,   25,    1,   37,    8,   21,\n",
       "            19,    5,    9,   14,   37,    2,    9,   14,   37,   26,   15,   12,\n",
       "            11,    5,   16,   12,    9],\n",
       "         [  14,    1,   13,    1,   37,   19,    1,   25,    1,   37,   19,    8,\n",
       "             1,    6,    9,   17,    1,    8,   37,    9,    4,    1,   25,   21,\n",
       "          -100, -100, -100, -100, -100]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    {'inputs': mel, 'labels': text[0]},\n",
    "    {'inputs': mel2, 'labels': text[1]}\n",
    "]\n",
    "batch = collator(features)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9925f35e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 392 ms, total: 1min 32s\n",
      "Wall time: 15.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(12.7206, grad_fn=<MeanBackward0>),\n",
       " tensor([[[-0.2438,  0.0271, -1.7649,  ..., -0.2794, -0.4674, -0.0894],\n",
       "          [ 0.2894,  0.1072, -1.9631,  ..., -0.4485, -0.7009, -0.1556],\n",
       "          [ 0.0792, -0.1594, -1.7579,  ...,  0.1081, -0.4064, -0.1305],\n",
       "          ...,\n",
       "          [ 0.0305, -0.4869, -1.2690,  ..., -0.1699, -0.1268,  0.1189],\n",
       "          [ 0.1104, -0.1468, -1.1248,  ..., -0.0366,  0.0917,  0.0816],\n",
       "          [-0.0622, -0.1821, -1.5775,  ..., -0.1951, -0.1715,  0.1808]],\n",
       " \n",
       "         [[-0.0265,  0.1000, -1.8042,  ..., -0.6123, -0.5839, -0.1483],\n",
       "          [-0.3110, -0.0191, -1.4859,  ..., -0.2943, -0.1898, -0.2667],\n",
       "          [-0.4550, -0.3622, -1.7746,  ..., -0.2279, -0.3193, -0.2250],\n",
       "          ...,\n",
       "          [ 0.2609,  0.7337, -0.9314,  ...,  0.4050,  0.0939, -0.2808],\n",
       "          [-0.4696,  0.5692, -0.6225,  ...,  0.5003,  0.3942, -0.2715],\n",
       "          [-0.4144,  0.1144, -0.7467,  ...,  0.8171, -0.1737, -0.2093]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([141,  88]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "encoder(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65280fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3937720"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(\n",
    "    param.numel() for param in encoder.parameters()\n",
    ")\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad04034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save_pretrained('./out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c525edd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16M\r\n",
      "-rw-r--r-- 1 husein husein  600 Jan  27 17:51 config.json\r\n",
      "-rw-rw-r-- 1 husein husein 2.5K Jan  27 17:51 conformer.py\r\n",
      "-rw-r--r-- 1 husein husein  16M Jan  27 17:51 model.safetensors\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50d769b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62f8bb24ab145f896a1b812008114a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/15.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/huseinzol05/conformer-tiny/commit/a406da2418c6cf1ff251ca6a585c18c3e5465682', commit_message='Upload ConformerEncoder', commit_description='', oid='a406da2418c6cf1ff251ca6a585c18c3e5465682', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.push_to_hub('huseinzol05/conformer-tiny', safe_serialization = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a219652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91d0066b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8819274c2a98479cb4673a380e2dc03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/600 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a19725ad7e4482494dc47ab78f68ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "conformer.py:   0%|          | 0.00/2.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/huseinzol05/conformer-tiny:\n",
      "- conformer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83c3615494647238d57160aa48a6cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/15.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('huseinzol05/conformer-tiny', trust_remote_code = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f43de060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConformerConfig {\n",
       "  \"_name_or_path\": \"huseinzol05/conformer-tiny\",\n",
       "  \"architectures\": [\n",
       "    \"ConformerEncoder\"\n",
       "  ],\n",
       "  \"auto_map\": {\n",
       "    \"AutoConfig\": \"huseinzol05/conformer-tiny--conformer.ConformerConfig\",\n",
       "    \"AutoModel\": \"huseinzol05/conformer-tiny--conformer.ConformerEncoder\"\n",
       "  },\n",
       "  \"conformer_depthwise_conv_kernel_size\": 31,\n",
       "  \"conformer_dropout\": 0.1,\n",
       "  \"conformer_ffn_dim\": 576,\n",
       "  \"conformer_input_dim\": 144,\n",
       "  \"conformer_num_heads\": 4,\n",
       "  \"conformer_num_layers\": 8,\n",
       "  \"ctc_loss_reduction\": \"mean\",\n",
       "  \"ctc_zero_infinity\": true,\n",
       "  \"input_dim\": 80,\n",
       "  \"model_type\": \"conformer\",\n",
       "  \"output_dim\": 40,\n",
       "  \"pad_token_id\": 39,\n",
       "  \"time_reduction_stride\": 4,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.35.2\"\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "929429f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 320 ms, total: 1min 31s\n",
      "Wall time: 15.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(12.6361, grad_fn=<MeanBackward0>),\n",
       " tensor([[[ 0.2286,  0.0527, -1.7409,  ..., -0.2106, -0.2741,  0.0191],\n",
       "          [ 0.0960,  0.2160, -1.7904,  ...,  0.1017, -0.6706, -0.3078],\n",
       "          [ 0.1767,  0.1828, -1.2174,  ..., -0.1274, -0.2793, -0.2420],\n",
       "          ...,\n",
       "          [-0.0634, -0.1707, -1.4293,  ..., -0.4739, -0.1507, -0.0820],\n",
       "          [-0.2105, -0.0901, -1.5113,  ..., -0.2044, -0.0864,  0.3093],\n",
       "          [ 0.2034, -0.0491, -1.4539,  ...,  0.0712, -0.5379, -0.2450]],\n",
       " \n",
       "         [[ 0.2148,  0.1968, -1.6583,  ..., -0.6372, -0.2747, -0.2175],\n",
       "          [-0.3147,  0.0349, -1.9579,  ..., -0.3642, -0.4155, -0.2894],\n",
       "          [ 0.2023,  0.3942, -1.9186,  ..., -0.1949, -0.2248, -0.1704],\n",
       "          ...,\n",
       "          [ 0.2204, -0.0192, -0.5200,  ...,  0.9203,  0.4959,  0.5512],\n",
       "          [-0.2399,  0.0558, -1.2872,  ...,  0.6316,  0.2812, -0.7079],\n",
       "          [ 0.3227,  0.2585, -1.1684,  ...,  0.5002,  0.1720, -0.4194]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([141,  88]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "encoder(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26364b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
