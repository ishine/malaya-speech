{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d13c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3.8 install pyctcdecode==0.1.0 pypi-kenlm==0.1.20220713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe02378",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "/home/husein/.local/lib/python3.8/site-packages/whisper/timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n",
      "`pyaudio` is not available, `malaya_speech.streaming.pyaudio` is not able to use.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from itertools import groupby\n",
    "import numpy as np\n",
    "import malaya_speech\n",
    "from malaya_speech.utils.char import decode as char_decode\n",
    "from transformers import AutoModel\n",
    "from conformer import HF_CTC_VOCAB, melspectrogram, ConformerConfig, ConformerEncoder\n",
    "from dataclasses import dataclass, field\n",
    "from huggingface_hub import hf_hub_download\n",
    "from pyctcdecode import build_ctcdecoder\n",
    "import kenlm\n",
    "\n",
    "HF_CTC_VOCAB_INDEX = {no: c for no, c in enumerate(HF_CTC_VOCAB)}\n",
    "HF_CTC_VOCAB_REV = {v: k for k, v in HF_CTC_VOCAB_INDEX.items()}\n",
    "\n",
    "ConformerConfig.register_for_auto_class()\n",
    "ConformerEncoder.register_for_auto_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f2a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = hf_hub_download('mesolitica/kenlm-pseudolabel-whisper-large-v3', 'out.binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a21ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kenlm_model = kenlm.Model(lm)\n",
    "decoder = build_ctcdecoder(\n",
    "    HF_CTC_VOCAB,\n",
    "    kenlm_model,\n",
    "    alpha=0.2,\n",
    "    beta=1.0,\n",
    "    ctc_token_idx=len(HF_CTC_VOCAB) - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18de3348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2M/checkpoint-121000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "latest = get_last_checkpoint('2M')\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "919a85ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(latest, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f8162e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12cc3d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "204f8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob('/home/husein/dev/malaya-speech/speech/example-speaker/*')\n",
    "ys = []\n",
    "for f in files:\n",
    "    try:\n",
    "        y, sr = malaya_speech.load(f)\n",
    "        ys.append(y)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceecd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "     def __call__(self, features):\n",
    "        inputs = [f['inputs'] for f in features]\n",
    "        lengths = torch.tensor([len(f['inputs']) for f in features])\n",
    "        inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first = True)\n",
    "        if 'labels' in features[0]:\n",
    "            labels = [torch.tensor(f['labels']) for f in features]\n",
    "            labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first = True, padding_value = -100)\n",
    "        else:\n",
    "            labels = None\n",
    "        return {\n",
    "            'inputs': inputs,\n",
    "            'lengths': lengths,\n",
    "            'labels': labels,\n",
    "        }\n",
    "    \n",
    "collator = DataCollatorCTCWithPadding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b285073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for y in ys:\n",
    "    mel = melspectrogram(y)\n",
    "    features.append({'inputs': mel})\n",
    "batch = collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "342beb95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 580 ms, sys: 70.6 ms, total: 651 ms\n",
      "Wall time: 56.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "r = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8a109e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nma saya suptar ida nn',\n",
       " 'scebut pecataan ani oke',\n",
       " 'testin nama saya usin binzo kpl k',\n",
       " 'takkan orang yang seperti abanm fakar itu mahu juga di menjaganya bai baik i orang yang tidak bertimbangberasa tu nnn',\n",
       " 'sebagai pembangkan yang matang dan sejahtera pas akan menghadapiplihan raya umu dan tidak menumbangkerajaan dari pintu belakangkne',\n",
       " 'pengatu caraan adalah swuatu keajah memberi arahan atau perinta kepada konpouter untuk menjalankan sesuatu jugas atau manda mana misin dali teran niekennn',\n",
       " 'tolonm sebul ati sata kn',\n",
       " 'apa kaba semua saya dowakan sedara dan setari sihat wala fiat hari i saya sekal lagi menemai searada']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = r[0].detach().numpy()\n",
    "argmax = np.argmax(logits, axis=-1)\n",
    "results = []\n",
    "for i in range(len(argmax)):\n",
    "    tokens = ''.join([HF_CTC_VOCAB_INDEX[k] for k in argmax[i]])\n",
    "    grouped_tokens = [token_group[0] for token_group in groupby(tokens)]\n",
    "    filtered_tokens = list(filter(lambda token: token != '_', grouped_tokens))\n",
    "    r = ''.join(filtered_tokens).strip()\n",
    "    results.append(r)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d07a998",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/husein/dev/malaya-speech/speech/example-speaker/shafiqah-idayu.wav nama saya suptar idau nama saya suptaridayu\n",
      "/home/husein/dev/malaya-speech/speech/example-speaker/mas-aisyah.wav scebut pecataan antir sebut perkataan anti\n",
      "/home/husein/dev/malaya-speech/speech/example-speaker/husein-zolkepli.wav testing nama saya usin binzo kpl testing nama saya usin binzokpli\n",
      "/home/husein/dev/malaya-speech/speech/example-speaker/female.wav takkan orang yang seperti abanm fakar itu mahu juga di menjaganya bai baik i orang yang tidak bertimbangberasa tu takkan orang yang seperti abang fakar itu mau juga dia menjaganya baik baik i orang yang tidak bertimbang rasa tu\n",
      "/home/husein/dev/malaya-speech/speech/example-speaker/haqkiem.wav sebagai pembangkan yang matang dan sejahtera pas akan menghadapiplihan raya umu medan tidak menumbangkerajaan dari pintu belakang sebagai pembangkang yang matang dan sejahtera pas akan menghadapi pilihan raya umum dan tidak menumbang kerajaan dari pintu belakang\n",
      "/home/husein/dev/malaya-speech/speech/example-speaker/husein-zolkepli-mixed-1.mp3 pengatu caraan adalah swuatu keajah memberi arahan atau perinta kepada konpouter untuk menjalankan sesuatu jugas atau manda mana misin daliteran i pengatucaraan adalah suatu kajah memberi arahan atau perintah kepada komputer untuk menjalankan sesuatu jugas atau mana mana mesin dali terani\n",
      "/home/husein/dev/malaya-speech/speech/example-speaker/husein-zolkepli-mixed-2.mp3 tolanm sebt ati sata tolong sebut ati sata\n",
      "/home/husein/dev/malaya-speech/speech/example-speaker/husein-generated.wav apa kaba semua saya dowakan sedara dan setari sihat wala fiat hari i saya sekal lagi menemai searada apa kabar semua saya doakan sedara dan setari sihat wala fiat hari ini saya sekali lagi menemui seara da\n"
     ]
    }
   ],
   "source": [
    "for f, y in zip(files, ys):\n",
    "    mel = melspectrogram(y)\n",
    "    inputs = {\n",
    "        'inputs': mel.unsqueeze(0),\n",
    "        'lengths': torch.tensor([len(mel)])\n",
    "    }\n",
    "    r = model(**inputs)\n",
    "    logits = r[0].detach().numpy()\n",
    "    argmax = np.argmax(logits, axis=-1)\n",
    "    tokens = ''.join([HF_CTC_VOCAB_INDEX[k] for k in argmax[0]])\n",
    "    grouped_tokens = [token_group[0] for token_group in groupby(tokens)]\n",
    "    filtered_tokens = list(filter(lambda token: token != '_', grouped_tokens))\n",
    "    r = ''.join(filtered_tokens).strip()\n",
    "    out = decoder.decode_beams(logits[0], prune_history=True)\n",
    "    d_lm, lm_state, timesteps, logit_score, lm_score = out[0]\n",
    "    print(f, r, d_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36c1c2fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd663c90d9f4475b05607c72d1bc23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/7.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/conformer-2M-ctc/commit/09ee6bda31271c0af3b6c76a1ebbfe8949812d63', commit_message='Upload ConformerEncoder', commit_description='', oid='09ee6bda31271c0af3b6c76a1ebbfe8949812d63', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('mesolitica/conformer-2M-ctc', safe_serialization = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
