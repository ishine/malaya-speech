{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d13c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3.8 install pyctcdecode==0.1.0 pypi-kenlm==0.1.20220713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe02378",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.7) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "/home/husein/.local/lib/python3.8/site-packages/whisper/timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n",
      "`pyaudio` is not available, `malaya_speech.streaming.pyaudio` is not able to use.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from itertools import groupby\n",
    "import numpy as np\n",
    "import malaya_speech\n",
    "from malaya_speech.utils.char import decode as char_decode\n",
    "from transformers import AutoModel\n",
    "from conformer import HF_CTC_VOCAB, melspectrogram, ConformerConfig, ConformerEncoder\n",
    "from dataclasses import dataclass, field\n",
    "from huggingface_hub import hf_hub_download\n",
    "from pyctcdecode import build_ctcdecoder\n",
    "import kenlm\n",
    "\n",
    "HF_CTC_VOCAB_INDEX = {no: c for no, c in enumerate(HF_CTC_VOCAB)}\n",
    "HF_CTC_VOCAB_REV = {v: k for k, v in HF_CTC_VOCAB_INDEX.items()}\n",
    "\n",
    "ConformerConfig.register_for_auto_class()\n",
    "ConformerEncoder.register_for_auto_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f2a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = hf_hub_download('mesolitica/kenlm-pseudolabel-whisper-large-v3', 'out.binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a21ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kenlm_model = kenlm.Model(lm)\n",
    "decoder = build_ctcdecoder(\n",
    "    HF_CTC_VOCAB,\n",
    "    kenlm_model,\n",
    "    alpha=0.2,\n",
    "    beta=1.0,\n",
    "    ctc_token_idx=len(HF_CTC_VOCAB) - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18de3348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tiny/checkpoint-1082300'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "latest = get_last_checkpoint('tiny')\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "919a85ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(latest, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f8162e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12cc3d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "204f8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob('/home/husein/dev/malaya-speech/speech/example-speaker/*')\n",
    "ys = []\n",
    "for f in files:\n",
    "    try:\n",
    "        y, sr = malaya_speech.load(f)\n",
    "        ys.append(y)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceecd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "     def __call__(self, features):\n",
    "        inputs = [f['inputs'] for f in features]\n",
    "        lengths = torch.tensor([len(f['inputs']) for f in features])\n",
    "        inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first = True)\n",
    "        if 'labels' in features[0]:\n",
    "            labels = [torch.tensor(f['labels']) for f in features]\n",
    "            labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first = True, padding_value = -100)\n",
    "        else:\n",
    "            labels = None\n",
    "        return {\n",
    "            'inputs': inputs,\n",
    "            'lengths': lengths,\n",
    "            'labels': labels,\n",
    "        }\n",
    "    \n",
    "collator = DataCollatorCTCWithPadding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b285073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for y in ys:\n",
    "    mel = melspectrogram(y)\n",
    "    features.append({'inputs': mel})\n",
    "batch = collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "342beb95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.82 s, sys: 332 ms, total: 2.15 s\n",
      "Wall time: 196 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "r = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8a109e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nama saya syafita idayu',\n",
       " 'cebut perkataan angka',\n",
       " 'testing nama saya usin bin zo caply',\n",
       " 'takkan orang yang seperti abang fakar itu mahu juga dia menjaganya baik baikeh orang yang tidak bertimbang rasa tu',\n",
       " 'sebagai pembangkang yang matang dan sejahtera pas akan menghadapi pilihan raya umum dan tidak menumbang kerajaan dari pintu belakang',\n",
       " 'pengatuh caraan adalah suatu keadah memberi arahan atau perintah kepada komputer untuk menjalankan sesuatu tugas atau mana mana mesin telektroni',\n",
       " 'tolong sbt anti kta',\n",
       " 'apa kabar semua saya doakan sedara dan sedari sihat walafiat hari ini saya sekali lagi menemui sedara da']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = r[0].detach().numpy()\n",
    "argmax = np.argmax(logits, axis=-1)\n",
    "results = []\n",
    "for i in range(len(argmax)):\n",
    "    tokens = ''.join([HF_CTC_VOCAB_INDEX[k] for k in argmax[i]])\n",
    "    grouped_tokens = [token_group[0] for token_group in groupby(tokens)]\n",
    "    filtered_tokens = list(filter(lambda token: token != '_', grouped_tokens))\n",
    "    r = ''.join(filtered_tokens).strip()\n",
    "    results.append(r)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d07a998",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/husein/dev/malaya-speech/speech/example-speaker/shafiqah-idayu.wav nama saya syafitah idayu nama saya syafiqah idayu a\n",
      "/home/husein/dev/malaya-speech/speech/example-speaker/mas-aisyah.wav sebut perkataan angka sebut perkataan angka\n",
      "/home/husein/dev/malaya-speech/speech/example-speaker/husein-zolkepli.wav testing nama saya musin bin zo kaply testing nama saya husin bin zokaply\n",
      "/home/husein/dev/malaya-speech/speech/example-speaker/female.wav t takkan orang yang seperti abang fakar itu mahu juga dia menjaganya baik baikeh orang yang tidak bertimbang rasa tu takkan orang yang seperti abang fakar itu mahu juga dia menjaganya baik baik eh orang yang tidak bertimbang rasa tu\n",
      "/home/husein/dev/malaya-speech/speech/example-speaker/haqkiem.wav sebagai pembangkang yang matang dan sejahtera pas akan menghadapi pilihan raya umum dan tidak menumbang kerajaan dari pintu belakang sebagai pembangkang yang matang dan sejahtera pas akan menghadapi pilihan raya umum dan tidak menumbang kerajaan dari pintu belakang\n",
      "/home/husein/dev/malaya-speech/speech/example-speaker/husein-zolkepli-mixed-1.mp3 pengatuhcaraan adalah suatu keadah memberi arahan atau perintah kepada komputer untuk menjalankan sesuatu tugas atau mana mana mesin telektroni pengatur caraan adalah suatu keadah memberi arahan atau perintah kepada komputer untuk menjalankan sesuatu tugas atau mana mana mesin telektroni\n",
      "/home/husein/dev/malaya-speech/speech/example-speaker/husein-zolkepli-mixed-2.mp3 tolong sebut ati kata tolong sebut anti kata\n",
      "/home/husein/dev/malaya-speech/speech/example-speaker/husein-generated.wav apa kabar semua saya doakan sedara dan sedari sihat walafiat hari ini saya sekali lagi menemui sedara da apa khabar semua saya doakan sedara dan sedari sihat walafiat hari ini saya sekali lagi menemui sedara dan\n"
     ]
    }
   ],
   "source": [
    "for f, y in zip(files, ys):\n",
    "    mel = melspectrogram(y)\n",
    "    inputs = {\n",
    "        'inputs': mel.unsqueeze(0),\n",
    "        'lengths': torch.tensor([len(mel)])\n",
    "    }\n",
    "    r = model(**inputs)\n",
    "    logits = r[0].detach().numpy()\n",
    "    argmax = np.argmax(logits, axis=-1)\n",
    "    tokens = ''.join([HF_CTC_VOCAB_INDEX[k] for k in argmax[0]])\n",
    "    grouped_tokens = [token_group[0] for token_group in groupby(tokens)]\n",
    "    filtered_tokens = list(filter(lambda token: token != '_', grouped_tokens))\n",
    "    r = ''.join(filtered_tokens).strip()\n",
    "    out = decoder.decode_beams(logits[0], prune_history=True)\n",
    "    d_lm, lm_state, timesteps, logit_score, lm_score = out[0]\n",
    "    print(f, r, d_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36c1c2fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbc3fcec2844ecbbfa80f25b5db123f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/15.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/conformer-tiny-ctc/commit/769d2eb0a6f9e6f22bca734f3793258066d2adb2', commit_message='Upload ConformerEncoder', commit_description='', oid='769d2eb0a6f9e6f22bca734f3793258066d2adb2', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('mesolitica/conformer-tiny-ctc', safe_serialization = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
