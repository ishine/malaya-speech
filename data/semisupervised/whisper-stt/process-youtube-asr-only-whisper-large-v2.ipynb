{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__name__))))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malaya_speech\n",
    "from malaya_speech import Pipeline\n",
    "from malaya_speech.utils.astype import float_to_int\n",
    "malaya_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_model = malaya_speech.vad.webrtc()\n",
    "p_vad = Pipeline()\n",
    "pipeline = (\n",
    "    p_vad.map(lambda x: malaya_speech.resample(x, old_samplerate = 22050, new_samplerate = 16000))\n",
    "    .map(lambda x: float_to_int(x, divide_max_abs=False))\n",
    "    .map(vad_model)\n",
    ")\n",
    "p_vad.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('filtered-youtube.json') as fopen:\n",
    "#     youtubes = json.load(fopen)\n",
    "# youtubes = youtubes[:len(youtubes) // 2]\n",
    "# len(youtubes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '/home/husein/ssd2/processed-youtube-asr-whisper-large-v3'\n",
    "# !rm -rf {parent_dir}\n",
    "!mkdir {parent_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir_done = '/home/husein/ssd2/processed-youtube-asr-whisper-large-v3-done'\n",
    "# !rm -rf {parent_dir_done}\n",
    "!mkdir {parent_dir_done}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from unidecode import unidecode\n",
    "\n",
    "youtubes_ = sorted(glob('/home/husein/ssd3/youtube/audio/*.mp3'))\n",
    "youtubes = []\n",
    "\n",
    "for f in youtubes_:\n",
    "    \n",
    "    new_f = unidecode(os.path.split(f)[1].replace('.mp3', '').replace(' ', '_'))\n",
    "    new_f = new_f.replace('/', '_')\n",
    "    f_done = os.path.join(parent_dir_done, new_f)\n",
    "    \n",
    "    if os.path.exists(f_done):\n",
    "        continue\n",
    "    youtubes.append(f)\n",
    "    \n",
    "youtubes = sorted(youtubes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(youtubes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model('large-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whisper.audio import (\n",
    "    FRAMES_PER_SECOND,\n",
    "    HOP_LENGTH,\n",
    "    N_FRAMES,\n",
    "    N_SAMPLES,\n",
    "    SAMPLE_RATE,\n",
    "    log_mel_spectrogram,\n",
    "    pad_or_trim,\n",
    ")\n",
    "\n",
    "def detect_lang(x):\n",
    "    mel = log_mel_spectrogram(y.astype('float32'), padding=N_SAMPLES)\n",
    "    content_frames = mel.shape[-1] - N_FRAMES\n",
    "    mel_segment = pad_or_trim(mel, N_FRAMES).to('cuda')\n",
    "    _, probs = model.detect_language(mel_segment)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = malaya_speech.load('/home/husein/dev/malaya-speech/speech/example-speaker/husein-zolkepli.wav', sr = 16000)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p_asr = Pipeline()\n",
    "resample = p_asr.map(lambda x: malaya_speech.resample(x, old_samplerate = 22050, new_samplerate = 16000))\n",
    "p = resample.map(lambda x: (\n",
    "    detect_lang(x),\n",
    "    model.transcribe(x.astype('float32'), task = 'transcribe', language = 'ms'),\n",
    "    model.transcribe(x.astype('float32'), task = 'transcribe', language = 'en'),\n",
    "), name = 'speech-to-text')\n",
    "p_asr.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = malaya_speech.load('/home/husein/dev/malaya-speech/speech/example-speaker/husein-zolkepli.wav', sr = 22050)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_asr(y)['speech-to-text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "import torchaudio\n",
    "import torch\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = glob('/home/husein/youtube/audio/(LANGSUNG)*')[2]\n",
    "# samples = malaya_speech.streaming.torchaudio.stream(f,\n",
    "#                                                         vad_model = p_vad,\n",
    "#                                                         asr_model = p_asr,\n",
    "#                                                         segment_length = 441,\n",
    "#                                                         realtime_print = True,\n",
    "#                                                         sample_rate = 22050,\n",
    "#                                                         min_length = 3.0,\n",
    "#                                                         max_length = 15.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import IPython.display as ipd\n",
    "# ipd.Audio(samples[1]['wav_data'], rate = 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in tqdm(youtubes):\n",
    "    \n",
    "    new_f = unidecode(os.path.split(f)[1].replace('.mp3', '').replace(' ', '_').replace('|', '_'))\n",
    "    new_f = new_f.replace('/', '_')\n",
    "    f_done = os.path.join(parent_dir_done, new_f)\n",
    "    \n",
    "    if os.path.exists(f_done):\n",
    "        continue\n",
    "    \n",
    "    samples = malaya_speech.streaming.torchaudio.stream(f, mode_utterence = False,\n",
    "                                                        vad_model = p_vad,\n",
    "                                                        asr_model = p_asr,\n",
    "                                                        segment_length = 441,\n",
    "                                                        realtime_print = False,\n",
    "                                                        sample_rate = 22050,\n",
    "                                                        min_length = 30.0,\n",
    "                                                        max_length = 30.0\n",
    "                                                       )\n",
    "    \n",
    "    if len(samples):\n",
    "        \n",
    "        parent_new_f = os.path.join(parent_dir, new_f)\n",
    "        os.makedirs(parent_new_f, exist_ok=True)\n",
    "\n",
    "        for i in range(len(samples)):\n",
    "            audio_path = os.path.join(parent_new_f, f'{i}.mp3')\n",
    "            torchaudio.save(audio_path, \n",
    "                            torch.tensor(samples[i]['wav_data'].astype('float32')).unsqueeze(0), \n",
    "                            22050, format='mp3')\n",
    "            samples[i]['wav_data'] = audio_path\n",
    "\n",
    "        with open(f'{parent_new_f}.pkl', 'wb') as fopen:\n",
    "            pickle.dump(samples, fopen)\n",
    "            \n",
    "    with open(f_done, 'w') as fopen:\n",
    "        fopen.write('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
