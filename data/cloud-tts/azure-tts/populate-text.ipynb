{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e930e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install azure-cognitiveservices-speech\n",
    "# !pip3 install malaya -U --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad76e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/wikidump1-raw.json\n",
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/dumping/news/dumping-news-6-july-2019.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2739f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "\n",
    "def to_ndarray(array):\n",
    "    \"\"\"\n",
    "    Change list / tuple / bytes into np.array\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    array: list / tuple / bytes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : np.array\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(array, list) or isinstance(array, tuple):\n",
    "        array = np.array(array)\n",
    "    elif isinstance(array, bytes) or isinstance(array, bytearray):\n",
    "        if isinstance(array, bytearray):\n",
    "            array = bytes(array)\n",
    "        array = np.frombuffer(array, np.int16)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c84be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "_pad = 'pad'\n",
    "_start = 'start'\n",
    "_eos = 'eos'\n",
    "_punctuation = \"!'(),.:;? \"\n",
    "_special = '-'\n",
    "_letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "MALAYA_SPEECH_SYMBOLS = (\n",
    "    [_pad, _start, _eos] + list(_special) + list(_punctuation) + list(_letters)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a243fbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 23:41:01.995554: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.5.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.5.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow_addons/utils/resource_loader.py:72: UserWarning: You are currently using TensorFlow 2.5.0 and trying to load a custom op (custom_ops/seq2seq/_beam_search_ops.so).\n",
      "TensorFlow Addons has compiled its custom ops against TensorFlow 2.4.0, and there are no compatibility guarantees between the two versions. \n",
      "This means that you might get segfaults when loading the custom op, or other kind of low-level errors.\n",
      " If you do, do not file an issue on Github. This is a known limitation.\n",
      "\n",
      "It might help you to fallback to pure Python ops with TF_ADDONS_PY_OPS . To do that, see https://github.com/tensorflow/addons#gpucpu-custom-ops \n",
      "\n",
      "You can also change the TensorFlow version installed on your system. You would need a TensorFlow version equal to or above 2.4.0 and strictly below 2.5.0.\n",
      " Note that nightly versions of TensorFlow, as well as non-pip TensorFlow like `conda install tensorflow` or compiled from source are not supported.\n",
      "\n",
      "The last solution is to find the TensorFlow Addons version that has custom ops compatible with the TensorFlow installed on your system. To do that, refer to the readme: https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/malaya_boilerplate/frozen_graph.py:28: UserWarning: Cannot import beam_search_ops from Tensorflow Addons, `deep_model` for stemmer will not available to use, make sure Tensorflow Addons version >= 0.12.0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import malaya\n",
    "from unidecode import unidecode\n",
    "\n",
    "normalizer = malaya.normalize.normalizer(date = False, time = False, money = True)\n",
    "\n",
    "def put_spacing_num(string):\n",
    "    string = re.sub('[A-Za-z]+', lambda ele: ' ' + ele[0] + ' ', string)\n",
    "    return re.sub(r'[ ]+', ' ', string).strip()\n",
    "\n",
    "def convert_to_ascii(string):\n",
    "    return unidecode(string)\n",
    "\n",
    "def collapse_whitespace(string):\n",
    "    return re.sub(_whitespace_re, ' ', string)\n",
    "\n",
    "def cleaning(string, normalize = True, add_eos = False):\n",
    "    sequence = []\n",
    "    string = convert_to_ascii(string)\n",
    "    string = re.sub(r'[ ]+', ' ', string).strip()\n",
    "    if string[-1] in ['-', ',']:\n",
    "        string = string[:-1]\n",
    "    if string[-1] != '.':\n",
    "        string = string + '.'\n",
    "    string = put_spacing_num(string)\n",
    "    string = re.sub(r'[ ]+', ' ', string).strip()\n",
    "    string = string\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47a9377a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LJ001-000001</td>\n",
       "      <td>Sultan Johor Sultan Ibrahim Iskandar selamat t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LJ002-000001</td>\n",
       "      <td>Menerusi entri terbaharu dalam laman Facebook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LJ003-000001</td>\n",
       "      <td>Kepulangan Sultan Ibrahim disambut oleh Tunku ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LJ004-000001</td>\n",
       "      <td>Sultan Ibrahim berlepas ke luar negara pada mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LJ005-000001</td>\n",
       "      <td>Kepulangan Sultan Ibrahim dijangka dapat menye...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0                                                  1\n",
       "0  LJ001-000001  Sultan Johor Sultan Ibrahim Iskandar selamat t...\n",
       "1  LJ002-000001  Menerusi entri terbaharu dalam laman Facebook ...\n",
       "2  LJ003-000001  Kepulangan Sultan Ibrahim disambut oleh Tunku ...\n",
       "3  LJ004-000001  Sultan Ibrahim berlepas ke luar negara pada mi...\n",
       "4  LJ005-000001  Kepulangan Sultan Ibrahim dijangka dapat menye..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('haqkiem/metadata.csv', header = None, sep = '|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a79d5d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beliau berkata, keseluruhan dadah dirampas seberat 656.9 gram dengan nilai RM 66836.50',\n",
       " 'Syarikat gergasi elektronik, Apple hari ini mengumumkan pendapatan suku tahunan sebanyak RM 374.68 bilion iaitu peningkatan sebanyak 9%',\n",
       " 'Penyanyi Ifa Raziah mengakui rasa takut apabila memakai barang kemas bernilai RM 3.5 juta sehinggakan terpaksa mengupah 3 orang pengawal',\n",
       " 'Pada majlis akad nikah itu, Eizlan telah menyerahkan mas kahwin sebanyak RM 80 dan sebentuk cincin berlian serta wang hantaran berjumlah RM 12,121.90',\n",
       " 'Bukan itu sahaja, koleksi filem Marvel ini lengkap dengan pakej bundle yang berharga antara RM 6 hingga RM 19.90 jer']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haqkiem_text = df[1].tolist()\n",
    "haqkiem_text = [text.split('.,,')[0] for text in haqkiem_text if len(re.findall(r'(RM \\d+,\\d+\\.\\d+|RM \\d+\\.\\d+)', text))]\n",
    "haqkiem_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eb1b13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beliau berkata , keseluruhan dadah dirampas seberat 656.9 gram dengan nilai RM 66836.50.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning(haqkiem_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cbe781b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beliau berkata , keseluruhan dadah dirampas seberat 656.9 gram dengan nilai RM 66836.50.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning(haqkiem_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80021fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 12, 18.6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_texts = []\n",
    "for t in haqkiem_text:\n",
    "    len_texts.append(len(t.split()))\n",
    "    \n",
    "np.max(len_texts), np.min(len_texts), np.mean(len_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "718355ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1748387"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('wikidump1-raw.json') as fopen:\n",
    "    wiki = json.load(fopen)\n",
    "    \n",
    "len(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "480bfccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399251"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('dumping-news-6-july-2019.json') as fopen:\n",
    "    news = json.load(fopen)\n",
    "    \n",
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e195be5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1748387/1748387 [00:01<00:00, 1365227.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "min_len = 2\n",
    "max_len = 20\n",
    "\n",
    "selected_wiki = []\n",
    "for t in tqdm(wiki):\n",
    "    l = len(t.split())\n",
    "    if min_len < l < max_len:\n",
    "        selected_wiki.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4ca098c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 399251/399251 [00:00<00:00, 1290666.23it/s]\n"
     ]
    }
   ],
   "source": [
    "selected_news = []\n",
    "for t in tqdm(news):\n",
    "    l = len(t.split())\n",
    "    if min_len < l < max_len:\n",
    "        selected_news.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87717544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1077492, 196733)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_wiki), len(selected_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "998207c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "samples = random.sample(selected_wiki, 20000) + random.sample(selected_news, 30000)\n",
    "samples = [{'text': t, 'cleaned': cleaning(t)} for t in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae5ef42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Sedangkan dalam bahasa Perancis, ''frire'' hanya bererti menggoreng di dalam minyak goreng yang banyak hingga terendam.\",\n",
       " 'cleaned': \"Sedangkan dalam bahasa Perancis , '' frire '' hanya bererti menggoreng di dalam minyak goreng yang banyak hingga terendam .\"}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdb3e30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:00<00:00, 3231159.87it/s]\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "for t in tqdm(samples):\n",
    "    lengths.append(len(t['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb249f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4445405"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "339fccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('populated-text.json', 'w') as fopen:\n",
    "    json.dump(samples, fopen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
