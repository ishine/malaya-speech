{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`pyaudio` is not available, `malaya_speech.streaming.pyaudio` is not able to use.\n"
     ]
    }
   ],
   "source": [
    "import malaya_speech\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.random import sample_without_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size (MB)</th>\n",
       "      <th>Quantized Size (MB)</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conformer-transducer</th>\n",
       "      <td>120</td>\n",
       "      <td>32.3</td>\n",
       "      <td>[malay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conformer-transducer-mixed</th>\n",
       "      <td>120</td>\n",
       "      <td>32.3</td>\n",
       "      <td>[malay, singlish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conformer-transducer-singlish</th>\n",
       "      <td>120</td>\n",
       "      <td>32.3</td>\n",
       "      <td>[singlish]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Size (MB) Quantized Size (MB)           Language\n",
       "conformer-transducer                120                32.3            [malay]\n",
       "conformer-transducer-mixed          120                32.3  [malay, singlish]\n",
       "conformer-transducer-singlish       120                32.3         [singlish]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malaya_speech.force_alignment.transducer.available_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 13:23:48.431277: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-11 13:23:48.479569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-11 13:23:48.482154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-11 13:23:48.482959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-11 13:23:48.818897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-11 13:23:48.819628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-11 13:23:48.820112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-11 13:23:48.820615: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-03-11 13:23:48.820631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 22302 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "2023-03-11 13:23:51.950118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-11 13:23:51.951004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-11 13:23:51.951692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-11 13:23:51.952204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-11 13:23:51.952634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-11 13:23:51.953083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22302 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "2023-03-11 13:23:57.325489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-11 13:23:57.326402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-11 13:23:57.327058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-11 13:23:57.327546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-11 13:23:57.327988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-11 13:23:57.328447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22302 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = malaya_speech.force_alignment.transducer.transformer(model = 'conformer-transducer', device = 'gpu:0')\n",
    "singlish_model = malaya_speech.force_alignment.transducer.transformer(model = 'conformer-transducer-singlish', device = 'gpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr = malaya_speech.stt.transducer.pt_transformer(model = 'mesolitica/conformer-medium-mixed')\n",
    "_ = asr.cuda()\n",
    "_ = asr.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open('/home/husein/ssd1/speech-bahasa/malay-asr-train.json') as fopen:\n",
    "    ms = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1635599"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ms['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/husein/malaya-speech/singlish-stt-train.json') as fopen:\n",
    "    sg = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3284901"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sg['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/husein/ssd2/imda/wav/5-75-tfrecord-1409.wav',\n",
       " '/home/husein/ssd2/imda/wav/5-118-tfrecord-1786.wav',\n",
       " '/home/husein/ssd2/imda/wav/4-77-tfrecord-2083.wav',\n",
       " '/home/husein/ssd2/imda/wav/2-39-tfrecord-78.wav',\n",
       " '/home/husein/ssd2/imda/wav/7-63-tfrecord-730.wav',\n",
       " '/home/husein/ssd2/imda/wav/5-68-tfrecord-1531.wav',\n",
       " '/home/husein/ssd2/imda/wav/0-17-tfrecord-3636.wav',\n",
       " '/home/husein/ssd2/imda/wav/1-113-tfrecord-1496.wav',\n",
       " '/home/husein/ssd2/imda/wav/7-108-tfrecord-1945.wav',\n",
       " '/home/husein/ssd2/imda/wav/5-63-tfrecord-3858.wav']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg['X'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and even like dogs at the shelter they just want to make you feel better',\n",
       " 'so for our annual annual package right now we having promotion is just one thousand',\n",
       " 'i still keep in contact with now',\n",
       " 'is armenia a nice place',\n",
       " 'yeah',\n",
       " 'a normal hawker centre with hybrid stalls',\n",
       " 'full tables of premiums can be found here',\n",
       " 'suggestions okay',\n",
       " 'okay so now to next call',\n",
       " 'ok so she said that now the innisfree has the new orchid line which cost']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg['Y'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "sr = 16000\n",
    "minimum = int(0.3 * sr)\n",
    "audio = Audio(sampling_rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby(alignment, length, min_threshold = 0.3):\n",
    "    r = []\n",
    "    g = []\n",
    "    for no, row in enumerate(alignment):\n",
    "        \n",
    "        if no > 0 and len(r) and alignment[no]['start'] - alignment[no-1]['end'] >= min_threshold:\n",
    "            g.append(r)\n",
    "            r = []\n",
    "        \n",
    "        r.append(row)\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'augmentation-switchboard-v5'\n",
    "!mkdir {directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate WER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    b = set(actual.split() + hyp.split())\n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "\n",
    "    w1 = [chr(word2char[w]) for w in actual.split()]\n",
    "    w2 = [chr(word2char[w]) for w in hyp.split()]\n",
    "\n",
    "    return Lev.distance(''.join(w1), ''.join(w2)) / len(actual.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                             | 1788/2000000 [1:15:07<1250:17:29,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 root error(s) found.\n",
      "  (0) Invalid argument: Integer division by zero\n",
      "\t [[node import/floordiv_1 (defined at home/husein/.local/lib/python3.8/site-packages/malaya_boilerplate/frozen_graph.py:384) ]]\n",
      "\t [[import/non_blank_transcript/_691]]\n",
      "  (1) Invalid argument: Integer division by zero\n",
      "\t [[node import/floordiv_1 (defined at home/husein/.local/lib/python3.8/site-packages/malaya_boilerplate/frozen_graph.py:384) ]]\n",
      "0 successful operations.\n",
      "0 derived errors ignored.\n",
      "\n",
      "Original stack trace for 'import/floordiv_1':\n",
      "  File \"usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n",
      "    await result\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"tmp/ipykernel_57589/4272912733.py\", line 2, in <module>\n",
      "    singlish_model = malaya_speech.force_alignment.transducer.transformer(model = 'conformer-transducer-singlish', device = 'gpu:0')\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/herpetologist/__init__.py\", line 100, in check\n",
      "    return func(*args, **kwargs)\n",
      "  File \"home/husein/dev/malaya-speech/malaya_speech/force_alignment/transducer.py\", line 66, in transformer\n",
      "    return stt.transducer_load(\n",
      "  File \"home/husein/dev/malaya-speech/malaya_speech/supervised/stt.py\", line 80, in transducer_load\n",
      "    g = load_graph(path['model'], **kwargs)\n",
      "  File \"home/husein/dev/malaya-speech/malaya_speech/utils/__init__.py\", line 48, in load_graph\n",
      "    return frozen_graph.load_graph(package, frozen_graph_filename, **kwargs)\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/malaya_boilerplate/frozen_graph.py\", line 384, in load_graph\n",
      "    tf.import_graph_def(graph_def)\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\", line 549, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/tensorflow/python/framework/importer.py\", line 400, in import_graph_def\n",
      "    return _import_graph_def_internal(\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/tensorflow/python/framework/importer.py\", line 513, in _import_graph_def_internal\n",
      "    _ProcessNewOps(graph)\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/tensorflow/python/framework/importer.py\", line 243, in _ProcessNewOps\n",
      "    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3711, in _add_new_tf_operations\n",
      "    new_ops = [\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3712, in <listcomp>\n",
      "    self._create_op_from_tf_operation(c_op, compute_device=compute_devices)\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3594, in _create_op_from_tf_operation\n",
      "    ret = Operation(c_op, self)\n",
      "  File \"home/husein/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 2045, in __init__\n",
      "    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                             | 7662/2000000 [5:23:53<1361:23:21,  2.46s/it]"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for O in tqdm(range(2000000)):\n",
    "    try:\n",
    "        i_ms = sample_without_replacement(len(ms['X']), 3)\n",
    "        i_sg = sample_without_replacement(len(sg['X']), 3)\n",
    "\n",
    "        groups = []\n",
    "        for i in i_ms:\n",
    "            x = ms['X'][i]\n",
    "            v = ms['Y'][i]\n",
    "            y = audio.decode_example(audio.encode_example(x))['array']\n",
    "            asr_ = asr.forward([y])[0]\n",
    "            \n",
    "            if asr_[0][1][0] < 0.07 and calculate_wer(v, asr_[0][0]) > 0.1:\n",
    "                # print(f'skip ms {i}', v, asr_[0][0], asr_[0][1][0])\n",
    "                continue\n",
    "                \n",
    "            result = model.predict(y, v)\n",
    "\n",
    "            if ' '.join([r['text'] for r in result['words_alignment']]) != v:\n",
    "                continue\n",
    "\n",
    "            grouped = groupby(result['words_alignment'], len(y) / sr)\n",
    "            # print(grouped)\n",
    "            for g in grouped:\n",
    "                y_ = y[int(g[0]['start'] * sr): int(g[-1]['end'] * sr) + minimum]\n",
    "                if len(y_):\n",
    "                    v_ = [g_['text'] for g_ in g]\n",
    "                    groups.append((y_, v_))\n",
    "\n",
    "        for i in i_sg:\n",
    "            x = sg['X'][i]\n",
    "            v = sg['Y'][i]\n",
    "            y = audio.decode_example(audio.encode_example(x))['array']\n",
    "            asr_ = asr.forward([y])[0]\n",
    "            \n",
    "            if asr_[0][1][0] < 0.1 and calculate_wer(v, asr_[0][0]) > 0.1:\n",
    "                # print(f'skip sg {i}', v, asr_[0][0], asr_[0][1][0])\n",
    "                continue\n",
    "                \n",
    "            result = singlish_model.predict(y, v)\n",
    "\n",
    "            if ' '.join([r['text'] for r in result['words_alignment']]) != v:\n",
    "                continue\n",
    "\n",
    "            grouped = groupby(result['words_alignment'], len(y) / sr)\n",
    "            for g in grouped:\n",
    "                y_ = y[int(g[0]['start'] * sr): int(g[-1]['end'] * sr) + minimum]\n",
    "                if len(y_):\n",
    "                    v_ = [g_['text'] for g_ in g]\n",
    "                    groups.append((y_, v_))\n",
    "\n",
    "        groups = shuffle(groups)\n",
    "        l = 0\n",
    "        combine_y, combine_v = [], []\n",
    "        index = 0\n",
    "        while l < 15 and index < len(groups):\n",
    "            l_ = len(groups[index][0]) / sr\n",
    "            if l_ < 1.0:\n",
    "                index += 1\n",
    "                continue\n",
    "            l += l_\n",
    "            combine_y.append(groups[index][0] / np.abs(groups[index][0]).max())\n",
    "            combine_v.extend(groups[index][1])\n",
    "            index += 1\n",
    "\n",
    "        if len(combine_v):\n",
    "            audio_path = f'{directory}/{O}.mp3'\n",
    "            torchaudio.save(audio_path, \n",
    "                            torch.tensor(np.concatenate(combine_y).astype('float32')).unsqueeze(0), \n",
    "                            sr, format='mp3')\n",
    "            data[O] = ' '.join(combine_v)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18112"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'augmentation-switchboard-v5'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('augment-switchboard-v5.json', 'w') as fopen:\n",
    "    json.dump(data, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
